{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vo44yrVwXnbq"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_rsSdFGXZF9"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "def format_time(elapsed):\n",
    "    \"\"\"Takes a time in seconds and returns a string hh:mm:ss.\"\"\"\n",
    "    elapsed_rounded = int(round(elapsed))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHz2V1yRXbPC"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_device():\n",
    "    if torch.backends.cuda.is_built():\n",
    "        print(\"CUDA\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_built():\n",
    "        print(\"mps\")\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        raise Exception(\"GPU is not avalaible!\")\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPB3eazRCcB2"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "import torch\n",
    "\n",
    "class MyBertMaxPoolClassifier(BertForSequenceClassification):\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "        last_hidden_state = outputs[0]  \n",
    "\n",
    "        extended_attention_mask = attention_mask.unsqueeze(-1).bool()\n",
    "        masked_hidden_state = last_hidden_state.masked_fill(~extended_attention_mask, float('-inf'))\n",
    "\n",
    "        \n",
    "        pooled_output, _ = torch.max(masked_hidden_state, dim=1)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "\n",
    "       \n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kak_eVglIZuH"
   },
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AttentionPoolBertClassifier(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.attention_layer = nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None\n",
    "    ):\n",
    "        \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict\n",
    "        )\n",
    "\n",
    "        \n",
    "        last_hidden_state = outputs[0]\n",
    "\n",
    "        \n",
    "        \n",
    "        attn_scores = self.attention_layer(last_hidden_state)\n",
    "        attn_scores = attn_scores.masked_fill(attention_mask.unsqueeze(-1) == 0, -1e9)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        pooled_output = torch.sum(last_hidden_state * attn_weights, dim=1)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states if output_hidden_states else None,\n",
    "            attentions=outputs.attentions if output_attentions else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dua9r0MCXeRC"
   },
   "outputs": [],
   "source": [
    "def train_eval_loop(\n",
    "    model, loader, optimizer, scheduler, device, n_epochs=2, seed_val=42\n",
    "):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    loss_values = []\n",
    "    t00 = time.time()\n",
    "\n",
    "    for epoch_i in range(0, n_epochs):\n",
    "        print(\"\")\n",
    "        print(\"======== Epoch {:} / {:} ========\".format(epoch_i + 1, n_epochs))\n",
    "        print(\"Training...\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(loader[\"train\"]):\n",
    "            b_input_ids, b_input_mask, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=b_input_ids,\n",
    "                attention_mask=b_input_mask,\n",
    "                token_type_ids=b_token_type_ids,\n",
    "                labels=b_labels\n",
    "            )\n",
    "            loss = outputs[0]\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(loader[\"train\"])\n",
    "        loss_values.append(avg_train_loss)\n",
    "\n",
    "        print(\"\\nAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(format_time(time.time() - t00)))\n",
    "\n",
    "        print(\"\\nRunning Validation...\")\n",
    "        t0 = time.time()\n",
    "        model.eval()\n",
    "        val_acc, nb_eval_steps = 0, 0\n",
    "\n",
    "        for batch in loader[\"validation\"]:\n",
    "            b_input_ids, b_input_mask, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(\n",
    "                    input_ids=b_input_ids,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    token_type_ids=b_token_type_ids\n",
    "                )[0]\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            logits = np.argmax(logits, axis=1).flatten()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "            val_acc += accuracy_score(logits, label_ids)\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        val_acc = 100 * (val_acc / nb_eval_steps)\n",
    "        print(\"  Validation ACC: {0:.2f}\".format(val_acc))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    return val_acc, loss_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlNeWQ9zXgU1"
   },
   "outputs": [],
   "source": [
    "def init_loader(max_length=16, batch_size=32, test_size=0.2, random_state=2023):\n",
    "    model_checkpoint = \"bert-base-uncased\"\n",
    "\n",
    "    dataset = load_dataset(\"glue\", \"rte\")\n",
    "\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "    df_s, x, y = {}, {}, {}\n",
    "    input_ids, attention_mask = {}, {}\n",
    "    token_type_ids = {}\n",
    "    datasets, loader = {}, {}\n",
    "\n",
    "    max_length = 128\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "\n",
    "        df_s[split] = dataset[split].to_pandas()\n",
    "\n",
    "        premise = dataset[split][\"sentence1\"]\n",
    "        hypothesis = dataset[split][\"sentence2\"]\n",
    "        y[split] = dataset[split][\"label\"]\n",
    "\n",
    "        x[split] = list(zip(premise, hypothesis))\n",
    "\n",
    "        input= tokenizer(\n",
    "            premise,\n",
    "            hypothesis,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "\n",
    "        input_ids[split], attention_mask[split],token_type_ids[split]  = input.input_ids, input.attention_mask,input.token_type_ids\n",
    "\n",
    "        Data.TensorDataset\n",
    "\n",
    "        datasets[split] = Data.TensorDataset(\n",
    "            input_ids[split], attention_mask[split], token_type_ids[split], torch.LongTensor(y[split])\n",
    "        )\n",
    "\n",
    "        loader[split] = Data.DataLoader(\n",
    "            datasets[split], batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "    return loader, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQtgoNL8XQ9z"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "def init_objects(\n",
    "    lr, n_epochs, max_length=16, batch_size=32, test_size=0.2, random_state=2023\n",
    "):\n",
    "    loader, _ = init_loader(max_length=max_length, batch_size=batch_size)\n",
    "\n",
    "    model = AttentionPoolBertClassifier.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "\n",
    "    total_steps = len(loader[\"train\"]) * n_epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    "    )\n",
    "    return model, loader, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtLbcOKCYX0L",
    "outputId": "f6af3ae8-749f-4ff3-a719-feccb2b71a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, alembic, optuna\n",
      "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install optuna\n",
    "import torch\n",
    "import optuna\n",
    "from transformers import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b15cb90bd0c4464e9e4a27a3bc27480a",
      "bbc6cc306c61406fb9e0444ea343cb76",
      "e8817510609149e2bc8663d864820575",
      "e7f653f75d9d4c7fbaa810f2b5304807",
      "4d3378f178754c5b813f81e986996692",
      "e4e82d2dcc5c45fabb5c755dce63eff6",
      "d5faa0b3f0c1481badfb8206dc14e83b",
      "acf503a7e9f8428d92d5c966d4e22d69",
      "3411d510b58842999eaf9127030d11bd",
      "8af4ddc27602432a811c247936bdd2a7",
      "273fa75d4da74c71ac14498e707d8c6a",
      "3e394ca04fed44d69a244bd16593ca5e",
      "90b231f7f77c4c6db5bec61990dfe629",
      "00a57f9f9f5f4dea80afa7a78c507a6d",
      "1b31baf0ed554b08b21f9792f27e11e5",
      "27b006d4b0f44450941d6b5837b20c0f",
      "f41bcaab4075469383ced6b2b0ed8dc2",
      "1ed7c20a1c4d42768ca3a7b228e0c97f",
      "902e1fa0fd5746aa90775c7d6082eee8",
      "d7eec640485844738b163f004b1a9193",
      "24bb28cf8ead46d2986028d07a38b5fd",
      "2aea1029119a472c97f4a00bb89d6e23",
      "8def23a1865142ed8a017df1ca983a60",
      "12e48abfadc64663ad35cd8206edcca4",
      "819684e08e6b461a9ad1127b5c570d28",
      "44d08ac062b44633b4cfc2c36d1b2f12",
      "3da6e9d5b0cb454c895da35e5ec953e8",
      "5e113b5700ff4617853f1cea42f78025",
      "4ef5cdac18b34f0fbe5be69212fdd5b9",
      "e3fa8fbd430a4a7481d72f403e1cb692",
      "900c971409454b6ab52cbb4db6702a31",
      "e2ed29e82a2140eaae8b8bcca6b92cf6",
      "f0a7795ee26649d480909962335d94bb",
      "daa55c2107eb4d7cb921efc5ef3c94df",
      "90412bf85a47440fbfb556af0d5678a2",
      "21aee13226ca4e5fb1c81ac61beadc8d",
      "8b2a45d6bdbe484b89a07b66e6151a23",
      "7c611d0f7a234ee780fac93ef92a846c",
      "d5f90b2bb421408e8f0ac806b29ac16a",
      "ec0b1a4dcace48d9aeab023c35a5f93e",
      "5f372fedea4f4536a21d10c808e8d93d",
      "fe944d0706c6445facadfd37f49c7c74",
      "bee012a0e50b42f7a03f55853145fe27",
      "e97fd90305264e559db18b7ae62511fc",
      "03b6dabfc6844453adb7aa0c5c8b7947",
      "2519e3a800cb4662b4a98ea7ba1630a8",
      "9a381ec81d4248b089139bf65b35d767",
      "7939901d604e4d6d81c0a9332f059167",
      "babf6a0c8fc746d6ba54dbe20ee5288e",
      "e73af59055e74c02ba027e3ca68d6d57",
      "8ff78391f1c64e6592bc825f43c057ca",
      "d8a165300a47464d90bbbb1f232ef31b",
      "ba7b72b9c1004d6094dab1b8d4d17787",
      "074e6abad84e40e8bdb34da8d26c8488",
      "cbe84caa83044dd68cb8e2d118545ad0",
      "1eff4f02629145a58ad17757a96440c9",
      "0b4123eab63e4127be15b631f7330f4d",
      "d6b39020f9ca4435bdf07a85b789e94d",
      "23ac511bf37a4172b88a5c491d7d8c9e",
      "ae82f13aad7649e5a62c07c09bec455a",
      "b886b0b264824755969fff247e68f6a9",
      "db11cc625db14843af481befbc29137e",
      "25f2af1639a54f75b8c79196cfc838f5",
      "3eac2d6af6b546bc845b13d4c0202b28",
      "88b61f17cc5d41368388daa328d059f9",
      "3e16a56a3d4e4074825b2674abf3d126",
      "abadcd32a01f4ade9c829f9380ea9341",
      "cbea2d7e72b24e86a7e8f56769e4c573",
      "1eafe8f8dcef47518d64f9e82b7db84d",
      "0087db0b75044bbf9a1c9c7f0b71eff5",
      "cee007f449e8455c8f545619e4602ae0",
      "91a9ff9b83fd48728e4690e1d8067388",
      "1a853933d21945dcbb34b2069be73125",
      "300dbe01533e46a980aad84af315e40d",
      "0fa6ebdaa15d4ebf8ced276fbe707243",
      "b1cc12ffb45c4238bedf5e3779373ad8",
      "83aa97d6f0eb4db39e5455aec6b6a92b",
      "48a9e271e3a24ec9b5ce9ffb7eae630c",
      "c4a25108ae6944bb83e4561f18879461",
      "250795b3c80a4dfb8445cf287aa75251",
      "c4f164aa2e9c4110b93bd9f2674698a6",
      "a73d78fd29954d9490d3565f22c02a95",
      "39c466c0528645c2aca90f05bf582861",
      "4161d7c304ef4c46b9f1a064022f410d",
      "cbcd4f6224ed410380cb556e19964864",
      "5ee2538ddbb346df8e34267bfd0d98fe",
      "126f75f2306c4fcda2bc2405901d9d65",
      "4e977aa0ba83493084cb1ccfe32eb86f",
      "1d8ee822404e48ed9e3504389911febb",
      "c1268679fb2a4f41bb99978c285a5e39",
      "04a629bc551a40cfb57f4f88b7102e56",
      "c1e4457ae5d44c259bec29846e74f774",
      "5d111b8a70fa4b07a79c9438bfb2971e",
      "bd92cd5f5bf04688b70fda67840d2e47",
      "8fe905e30b2f449faa8368e6a972a2be",
      "314cc138c42249d5b2b93b757ecaaf37",
      "506ae86482e3442eb92dd7a11b034507",
      "2eca3dce7561427c9481e97c08a2abfe",
      "73d17b7108cf46d48b16ed42bad87252",
      "80d151faef4f40e7ad457ca59e22d1ed",
      "11e4ad4560564ec7af3ad8a61a8c7947",
      "a9a87bbbed9d4ee9b0cd4848127f2a1a",
      "9b83e48cfaba4f47b46a6afd0ca88b1b",
      "d9d911cff16346dd8b32ec3ffbc8b217",
      "298939df6d45482ea6915556758e65f2",
      "88fccf982b6942c59691ff6c063f1ea8",
      "94f805b5abe54650a2e44ef0a9c827f5",
      "39f39c170ca5453fb6dc6767b2f986c5",
      "50536a201ecd42fe85d459865b624db6",
      "9388c50aaf8f47c8b6fcb8e18986159f",
      "d6072c4a80284866870d4e6b07648996",
      "6f11b13c09fc4599884b0175373e2a04",
      "bda216c7159f47a8869e2d7fa7330e56",
      "6c8202edcb5a4ea09808531749ae0a92",
      "9add08c94f284089bd62621114f14f25",
      "58a3c00ad35a452d865b3a8acfcf3033",
      "ad187e7f74554e1988b9781c696be706",
      "495ee20e09df41da8c72dbb82d7019fd",
      "1b1cb9abdd8b4423939bf6c8e5bedc6b",
      "f6b8cafacdca47839604cf47066ab75a",
      "8e13c717453e4bf3b073d23d63c16b58",
      "6a802f5889c44906bd6ef0c07b7dcbe8",
      "fe09bc9747bf4c44978e06894e0b35e3",
      "625082d47f41498ab72506d1d21182cf",
      "622d2d1759044370b20f77cc14aa34e3",
      "7d72b6044262439b91c70004ff8b0351",
      "61ec7bef3cc94007ab7599f23cc2ba7d",
      "e7b88d04f2914ec08928ec5975d4bdfa",
      "952834ab7c1c4748a06b67bdf1b7fc13",
      "0c2e22dbb3914ef195fee66957074a2f",
      "c56d982e4ae748b8bad7c2c145ac1804",
      "49d8c8022b89443fa75c838b19ad600b"
     ]
    },
    "id": "gjLlanaWZ4xK",
    "outputId": "1add6328-1f94-42a8-f119-b3b8444a1dee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15cb90bd0c4464e9e4a27a3bc27480a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e394ca04fed44d69a244bd16593ca5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/584k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8def23a1865142ed8a017df1ca983a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/69.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa55c2107eb4d7cb921efc5ef3c94df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/621k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b6dabfc6844453adb7aa0c5c8b7947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eff4f02629145a58ad17757a96440c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abadcd32a01f4ade9c829f9380ea9341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a9e271e3a24ec9b5ce9ffb7eae630c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8ee822404e48ed9e3504389911febb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d151faef4f40e7ad457ca59e22d1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6072c4a80284866870d4e6b07648996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a802f5889c44906bd6ef0c07b7dcbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AttentionPoolBertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (attention_layer): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 2e-5\n",
    "n_epochs = 1\n",
    "max_length = 16\n",
    "batch_size = 32\n",
    "test_size = 0.2\n",
    "random_state = 2023\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(\n",
    "    lr, n_epochs, max_length, batch_size, test_size, random_state\n",
    ")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI5S0IxbavsJ",
    "outputId": "1fc48cbf-faf2-4bf1-b68f-03f939bcf2c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.00\n",
      "  Validation took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "_, _ = train_eval_loop(\n",
    "    model, loader, optimizer, scheduler, device, n_epochs=n_epochs, seed_val=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrEO8agacAPX",
    "outputId": "2f04b61b-9561-470c-bc27-833628858c6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:47:08,819] A new study created in memory with name: Stduy 0\n",
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 51.14\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:47:35,951] Trial 0 finished with value: 50.95899470899471 and parameters: {'lr': 4.75181067704919e-06, 'n_epochs': 2, 'max_length': 64, 'batch_size': 32}. Best is trial 0 with value: 50.95899470899471.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 50.96\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.06\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.03\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:48:18,773] Trial 1 finished with value: 54.02777777777777 and parameters: {'lr': 3.881703153788711e-06, 'n_epochs': 3, 'max_length': 32, 'batch_size': 16}. Best is trial 1 with value: 54.02777777777777.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 54.03\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.72\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.65\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 57.85\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.62\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:49:01,747] Trial 2 finished with value: 55.76388888888889 and parameters: {'lr': 1.2076887034636962e-05, 'n_epochs': 3, 'max_length': 16, 'batch_size': 16}. Best is trial 2 with value: 55.76388888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 55.76\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.80\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.10\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:49:29,344] Trial 3 finished with value: 51.66997354497354 and parameters: {'lr': 1.4690620663130575e-06, 'n_epochs': 2, 'max_length': 32, 'batch_size': 32}. Best is trial 2 with value: 55.76388888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 51.67\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.08\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.84\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:50:08,480] Trial 4 finished with value: 53.720238095238095 and parameters: {'lr': 1.1616289310589247e-05, 'n_epochs': 3, 'max_length': 32, 'batch_size': 32}. Best is trial 2 with value: 55.76388888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 53.72\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.51\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:50:35,604] Trial 5 finished with value: 56.71296296296296 and parameters: {'lr': 1.2225251522321694e-05, 'n_epochs': 2, 'max_length': 16, 'batch_size': 32}. Best is trial 5 with value: 56.71296296296296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.71\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 50.28\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 52.01\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 51.94\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:53\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:51:33,814] Trial 6 finished with value: 52.29166666666667 and parameters: {'lr': 1.3624281853312044e-06, 'n_epochs': 4, 'max_length': 64, 'batch_size': 16}. Best is trial 5 with value: 56.71296296296296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 52.29\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.19\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.93\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.28\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:53\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:52:31,034] Trial 7 finished with value: 54.58333333333333 and parameters: {'lr': 2.1022475445490807e-06, 'n_epochs': 4, 'max_length': 64, 'batch_size': 16}. Best is trial 5 with value: 56.71296296296296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 54.58\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 50.74\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.24\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:53:08,214] Trial 8 finished with value: 53.55654761904762 and parameters: {'lr': 5.491146747732536e-06, 'n_epochs': 3, 'max_length': 64, 'batch_size': 64}. Best is trial 5 with value: 56.71296296296296.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 53.56\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.73\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.74\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.64\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.24\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.62\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:53:56,270] Trial 9 finished with value: 58.31845238095238 and parameters: {'lr': 1.7559589889568154e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 58.32\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.40\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.64\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 57.34\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.60\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.57\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:54:44,362] Trial 10 finished with value: 56.08630952380953 and parameters: {'lr': 2.9336793455741386e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.09\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.17\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:55:12,947] Trial 11 finished with value: 54.80654761904762 and parameters: {'lr': 2.1308280054307903e-05, 'n_epochs': 2, 'max_length': 16, 'batch_size': 64}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 54.81\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.60\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.27\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.88\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.65\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:56:06,606] Trial 12 finished with value: 54.211309523809526 and parameters: {'lr': 1.2571336212999336e-05, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 54.21\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.62\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:56:41,702] Trial 13 finished with value: 56.66335978835979 and parameters: {'lr': 8.979223534017073e-06, 'n_epochs': 2, 'max_length': 16, 'batch_size': 32}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.66\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 51.67\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.63\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.73\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.61\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:57:36,697] Trial 14 finished with value: 56.08630952380953 and parameters: {'lr': 1.9296623020494705e-05, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.09\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.15\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:58:10,878] Trial 15 finished with value: 56.66335978835979 and parameters: {'lr': 7.416392316285699e-06, 'n_epochs': 2, 'max_length': 64, 'batch_size': 32}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.66\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.90\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:58:47,792] Trial 16 finished with value: 52.61904761904762 and parameters: {'lr': 1.8235090772763022e-05, 'n_epochs': 2, 'max_length': 16, 'batch_size': 64}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 52.62\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.78\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.62\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.21\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.56\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.88\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.50\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 12:59:45,590] Trial 17 finished with value: 57.04365079365079 and parameters: {'lr': 2.765584874583562e-05, 'n_epochs': 4, 'max_length': 16, 'batch_size': 32}. Best is trial 9 with value: 58.31845238095238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 57.04\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.86\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.62\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 62.24\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.55\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.29\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.50\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 13:00:51,874] Trial 18 finished with value: 59.639550264550266 and parameters: {'lr': 2.933404523818007e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 32}. Best is trial 18 with value: 59.639550264550266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 59.64\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.73\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 51.06\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.87\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.18\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 13:01:56,371] Trial 19 finished with value: 54.80654761904762 and parameters: {'lr': 3.0249242274371735e-06, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 18 with value: 59.639550264550266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 54.81\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.72\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.85\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.13\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.64\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.38\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.63\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 13:02:53,735] Trial 20 finished with value: 55.75892857142857 and parameters: {'lr': 1.685196833452587e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 18 with value: 59.639550264550266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 55.76\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.46\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.63\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.09\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.56\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 60.68\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.52\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 13:03:52,519] Trial 21 finished with value: 61.37566137566137 and parameters: {'lr': 2.4385374317676526e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 32}. Best is trial 21 with value: 61.37566137566137.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 61.38\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.11\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.63\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.62\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.56\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 61.03\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.52\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 13:04:52,284] Trial 22 finished with value: 61.02843915343915 and parameters: {'lr': 2.486931777944464e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 32}. Best is trial 21 with value: 61.37566137566137.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 61.03\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.68\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.62\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.28\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.54\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 60.52\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.48\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 13:05:49,593] Trial 23 finished with value: 60.16865079365079 and parameters: {'lr': 2.8641112391992403e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 32}. Best is trial 21 with value: 61.37566137566137.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 60.17\n",
      "  Validation took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_dict = {\n",
    "    \"lr\": [1e-6, 3e-5],\n",
    "    \"n_epochs\": [2,3,4],\n",
    "    \"max_length\": [16, 32, 64],\n",
    "    \"batch_size\": [16, 32,64],\n",
    "}\n",
    "\n",
    "\n",
    "class BertObjective:\n",
    "    def __init__(self, d, device):\n",
    "        self.d = d\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, trial: optuna.trial.Trial):\n",
    "        self.lr = trial.suggest_float(\"lr\", self.d[\"lr\"][0], self.d[\"lr\"][1], log=True)\n",
    "        self.n_epochs = trial.suggest_categorical(\"n_epochs\", self.d[\"n_epochs\"])\n",
    "        self.max_length = trial.suggest_categorical(\"max_length\", self.d[\"max_length\"])\n",
    "        self.batch_size = trial.suggest_categorical(\"batch_size\", self.d[\"batch_size\"])\n",
    "\n",
    "        model, loader, optimizer, scheduler = init_objects(\n",
    "            self.lr, self.n_epochs, self.max_length, self.batch_size\n",
    "        )\n",
    "        model.to(self.device)\n",
    "        val_acc, _ = train_eval_loop(\n",
    "            model, loader, optimizer, scheduler, self.device, self.n_epochs\n",
    "        )\n",
    "\n",
    "        return val_acc\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "study = optuna.create_study(study_name=\"Stduy 0\", direction=\"maximize\")\n",
    "study.optimize(BertObjective(param_dict, device), n_trials=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvdkcJa3b9RQ",
    "outputId": "70660837-a8ef-4142-b1de-f158d73bf154"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MyBertMaxPoolClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.71\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.46\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.63\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.09\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.56\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 60.68\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.52\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 61.38\n",
      "  Validation took: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train again with best parameters\n",
    "lr = study.best_params[\"lr\"]\n",
    "n_epochs = study.best_params[\"n_epochs\"]\n",
    "max_length = study.best_params[\"max_length\"]\n",
    "batch_size = study.best_params[\"batch_size\"]\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size)\n",
    "model.to(device)\n",
    "val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs)\n",
    "# Obtain Test Results\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Lsv1RkGb92o",
    "outputId": "fa680dec-ead1-4e9c-d2dd-7451ddfc0d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Learning Rate  Epochs  Max Length  Batch Size\n",
      "      0.000024       4          64          32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "best_params = {\n",
    "    \"Learning Rate\": study.best_params[\"lr\"],\n",
    "    \"Epochs\": study.best_params[\"n_epochs\"],\n",
    "    \"Max Length\": study.best_params[\"max_length\"],\n",
    "    \"Batch Size\": study.best_params[\"batch_size\"]\n",
    "}\n",
    "\n",
    "best_params_df = pd.DataFrame([best_params])\n",
    "print(best_params_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu0uXI44ImXJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VK2dp0UoImr0",
    "outputId": "570cb433-3231-4c7e-f9de-1bc20b9d1984"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:44:21,399] A new study created in memory with name: Stduy 0\n",
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.56\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 57.64\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:45:03,966] Trial 0 finished with value: 56.87500000000001 and parameters: {'lr': 4.360915124784374e-06, 'n_epochs': 3, 'max_length': 64, 'batch_size': 16}. Best is trial 0 with value: 56.87500000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.88\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 58.66\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 62.43\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 62.74\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:45:52,250] Trial 1 finished with value: 60.848214285714285 and parameters: {'lr': 2.1024437666652437e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 60.85\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.31\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.27\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 58.61\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:46:43,201] Trial 2 finished with value: 57.55621693121693 and parameters: {'lr': 3.3969354542575265e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 32}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 57.56\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.37\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 57.15\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:39\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:47:25,728] Trial 3 finished with value: 58.12500000000001 and parameters: {'lr': 3.5798365989873304e-06, 'n_epochs': 3, 'max_length': 16, 'batch_size': 16}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 58.13\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.32\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 57.41\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.64\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.86\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.62\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:48:16,257] Trial 4 finished with value: 57.20899470899471 and parameters: {'lr': 8.180286803974599e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 32}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 57.21\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.57\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.31\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:36\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:48:55,748] Trial 5 finished with value: 57.20899470899471 and parameters: {'lr': 3.199977084716165e-06, 'n_epochs': 3, 'max_length': 16, 'batch_size': 32}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 57.21\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 62.15\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.53\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:49:25,186] Trial 6 finished with value: 59.30555555555556 and parameters: {'lr': 2.8042621727559996e-05, 'n_epochs': 2, 'max_length': 32, 'batch_size': 16}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 59.31\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 53.27\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.20\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:50:02,218] Trial 7 finished with value: 54.50892857142857 and parameters: {'lr': 1.0172115185003336e-05, 'n_epochs': 3, 'max_length': 32, 'batch_size': 64}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 54.51\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.73\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:24\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:50:29,634] Trial 8 finished with value: 58.63095238095239 and parameters: {'lr': 3.4438951349849567e-06, 'n_epochs': 2, 'max_length': 64, 'batch_size': 32}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 58.63\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.18\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:26\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.58\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.63\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:51:12,147] Trial 9 finished with value: 59.166666666666664 and parameters: {'lr': 7.395349036197772e-06, 'n_epochs': 3, 'max_length': 32, 'batch_size': 16}. Best is trial 1 with value: 60.848214285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 59.17\n",
      "  Validation took: 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 61.47\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 61.16\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 60.85\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:52:00,176] Trial 10 finished with value: 61.78571428571429 and parameters: {'lr': 1.0466689418484104e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 61.79\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.90\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:52:48,175] Trial 11 finished with value: 56.458333333333336 and parameters: {'lr': 1.050026477213232e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.90\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.15\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:53:35,546] Trial 12 finished with value: 56.458333333333336 and parameters: {'lr': 1.023325802148113e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 57.08\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.24\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.49\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:54:22,835] Trial 13 finished with value: 55.803571428571416 and parameters: {'lr': 1.75503850612844e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 55.80\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.55\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.18\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.80\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:55:10,326] Trial 14 finished with value: 56.74107142857142 and parameters: {'lr': 1.960365261746454e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.74\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.44\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.55\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.80\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:55:57,499] Trial 15 finished with value: 55.49107142857142 and parameters: {'lr': 1.816215147285858e-06, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 55.49\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.77\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:56:22,563] Trial 16 finished with value: 56.77083333333333 and parameters: {'lr': 1.8183923861854142e-06, 'n_epochs': 2, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.77\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 47.01\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 49.52\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 50.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:57:09,882] Trial 17 finished with value: 49.82142857142857 and parameters: {'lr': 1.3188883435219846e-06, 'n_epochs': 4, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 49.82\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.55\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.49\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.18\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:57:57,268] Trial 18 finished with value: 56.42857142857143 and parameters: {'lr': 2.4293234909440323e-06, 'n_epochs': 4, 'max_length': 32, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.43\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.84\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.66\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 58.01\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.63\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.26\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.60\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:58:45,838] Trial 19 finished with value: 59.86607142857142 and parameters: {'lr': 1.3629947563516654e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 59.87\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 55.52\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:59:10,626] Trial 20 finished with value: 55.833333333333336 and parameters: {'lr': 1.320972614455104e-06, 'n_epochs': 2, 'max_length': 16, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 55.83\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.21\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.65\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 58.30\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.60\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 58.62\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.56\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 16:59:58,467] Trial 21 finished with value: 61.75595238095239 and parameters: {'lr': 1.573383649780384e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 61.76\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.41\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.64\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 59.88\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.56\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 58.63\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.48\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 17:00:46,167] Trial 22 finished with value: 59.25595238095238 and parameters: {'lr': 2.070094313904429e-05, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 59.26\n",
      "  Validation took: 0:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.55\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.12\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.68\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 57.34\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.67\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-07 17:01:33,764] Trial 23 finished with value: 56.08630952380953 and parameters: {'lr': 5.329121742275755e-06, 'n_epochs': 4, 'max_length': 64, 'batch_size': 64}. Best is trial 10 with value: 61.78571428571429.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation ACC: 56.09\n",
      "  Validation took: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_dict = {\n",
    "    \"lr\": [1e-6, 3e-5],\n",
    "    \"n_epochs\": [2,3,4],\n",
    "    \"max_length\": [16, 32, 64],\n",
    "    \"batch_size\": [16, 32,64],\n",
    "}\n",
    "\n",
    "\n",
    "class BertObjective:\n",
    "    def __init__(self, d, device):\n",
    "        self.d = d\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, trial: optuna.trial.Trial):\n",
    "        self.lr = trial.suggest_float(\"lr\", self.d[\"lr\"][0], self.d[\"lr\"][1], log=True)\n",
    "        self.n_epochs = trial.suggest_categorical(\"n_epochs\", self.d[\"n_epochs\"])\n",
    "        self.max_length = trial.suggest_categorical(\"max_length\", self.d[\"max_length\"])\n",
    "        self.batch_size = trial.suggest_categorical(\"batch_size\", self.d[\"batch_size\"])\n",
    "\n",
    "        model, loader, optimizer, scheduler = init_objects(\n",
    "            self.lr, self.n_epochs, self.max_length, self.batch_size\n",
    "        )\n",
    "        model.to(self.device)\n",
    "        val_acc, _ = train_eval_loop(\n",
    "            model, loader, optimizer, scheduler, self.device, self.n_epochs\n",
    "        )\n",
    "\n",
    "        return val_acc\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "study = optuna.create_study(study_name=\"Stduy 0\", direction=\"maximize\")\n",
    "study.optimize(BertObjective(param_dict, device), n_trials=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDnPEy6ZI1l3",
    "outputId": "ea0f7cc5-aa2a-4110-bc66-47fad0ceda0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AttentionPoolBertClassifier were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['attention_layer.bias', 'attention_layer.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.70\n",
      "  Training epoch took: 0:00:11\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 54.90\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:22\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.15\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "Average training loss: 0.69\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n",
      "  Validation ACC: 56.46\n",
      "  Validation took: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train again with best parameters\n",
    "lr = study.best_params[\"lr\"]\n",
    "n_epochs = study.best_params[\"n_epochs\"]\n",
    "max_length = study.best_params[\"max_length\"]\n",
    "batch_size = study.best_params[\"batch_size\"]\n",
    "\n",
    "model, loader, optimizer, scheduler = init_objects(lr, n_epochs, max_length, batch_size)\n",
    "model.to(device)\n",
    "val_acc, _ = train_eval_loop(model, loader, optimizer, scheduler, device, n_epochs)\n",
    "# Obtain Test Results\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KfwXcXJM_5o",
    "outputId": "e82a55de-cee0-4530-d910-9654083fc5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Learning Rate  Epochs  Max Length  Batch Size\n",
      "      0.000001       4          16          64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "best_params = {\n",
    "    \"Learning Rate\": study.best_params[\"lr\"],\n",
    "    \"Epochs\": study.best_params[\"n_epochs\"],\n",
    "    \"Max Length\": study.best_params[\"max_length\"],\n",
    "    \"Batch Size\": study.best_params[\"batch_size\"]\n",
    "}\n",
    "\n",
    "best_params_df = pd.DataFrame([best_params])\n",
    "print(best_params_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dv4jgy2iNRZW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
